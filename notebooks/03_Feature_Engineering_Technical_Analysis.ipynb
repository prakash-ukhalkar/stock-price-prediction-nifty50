{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stock Price Prediction - NIFTY 50**\n",
    "\n",
    "### **Notebook 03: Feature Engineering and Technical Analysis**\n",
    "\n",
    "[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/) [![Pandas](https://img.shields.io/badge/Pandas-Latest-green)](https://pandas.pydata.org/) [![TA-Lib](https://img.shields.io/badge/TA--Lib-Latest-purple)](https://github.com/mrjbq7/ta-lib) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
    "\n",
    "---\n",
    "\n",
    "**Part of the comprehensive learning series:** [Stock Price Prediction - NIFTY 50](https://github.com/prakash-ukhalkar/stock-price-prediction-nifty50)\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Transform raw OHLCV data into sophisticated technical indicators\n",
    "- Create lagged features for time series prediction\n",
    "- Generate momentum indicators (RSI, MACD) and trend indicators (MA, EMA)\n",
    "- Implement volume and volatility-based features\n",
    "- Prepare feature-rich dataset for machine learning models\n",
    "\n",
    "**Dataset Scope:** Engineer features from training data. Create technical indicators and lag variables for modeling.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "* We load the clean training data (`nifty50_train.csv`) generated in Notebook 02, as feature engineering should be performed only on the training set to prevent **data leakage** into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully. Shape: (57360, 12)\n",
      "Initial Columns:  ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Symbol', 'Log_Return', 'Simple_Return', 'Price_Change', 'Price_Change_Pct']\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Install 'ta' (if necessary)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta # For Technical Analysis\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set path to be able to import custom utility functions from src/\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "# Assuming a basic __init__.py in src/features for now. \n",
    "# For simplicity, TAs are generated directly using the 'ta' library here.\n",
    "\n",
    "TRAIN_DATA_PATH = '../data/processed/nifty50_train.csv'\n",
    "\n",
    "# Load the training dataset\n",
    "df_train = pd.read_csv(TRAIN_DATA_PATH, index_col='Date', parse_dates=True)\n",
    "\n",
    "print(f\"Training data loaded successfully. Shape: {df_train.shape}\")\n",
    "print(\"Initial Columns: \", df_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Step I: Lag Features\n",
    "\n",
    "**Fundamental Concept:** \n",
    "\n",
    "  * For time series forecasting, the most powerful predictors of the future price are often the price and returns from the immediate past. \n",
    "\n",
    "  * **Lag features** transform the time series problem into a supervised learning problem.\n",
    "\n",
    "  * We create lags for the Closing Price and Log Returns for various steps back to capture short-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created lagged features for periods: [1, 2, 3, 5, 10]\n",
      "Current columns: 22\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Create Lagged Price Features\n",
    "LAG_PERIODS = [1, 2, 3, 5, 10]\n",
    "\n",
    "for lag in LAG_PERIODS:\n",
    "    # Lagged Closing Price: Price from 'lag' days ago\n",
    "    df_train[f'Close_Lag_{lag}'] = df_train['Close'].shift(lag)\n",
    "    \n",
    "    # Lagged Log Returns: Return from 'lag' days ago\n",
    "    df_train[f'Return_Lag_{lag}'] = df_train['Log_Return'].shift(lag)\n",
    "    \n",
    "print(f\"Created lagged features for periods: {LAG_PERIODS}\")\n",
    "print(f\"Current columns: {df_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering Step II: Technical Indicators (TA)\n",
    "\n",
    "**Research Objective:** \n",
    "\n",
    "  * The research project explicitly targets indicators such as **Moving Averages (MA)**, **Relative Strength Index (RSI)**, and **Volume**. \n",
    "  \n",
    "  * TAs act as secondary features that summarize price and volume action, providing momentum, volatility, and trend signals for the machine learning models.\n",
    "\n",
    "  * We use the dedicated `ta` Python library to generate industry-standard indicators efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Trend Indicators (Moving Averages)\n",
    "\n",
    "* Moving Averages smooth the price data to identify the trend direction. \n",
    "\n",
    "* We include Simple Moving Average (SMA) and Exponential Moving Average (EMA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend Indicators (MA, EMA, MACD) created.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Trend Indicators\n",
    "WINDOW_TREND = [10, 20, 50] # Short, Medium, Long-term windows\n",
    "\n",
    "for window in WINDOW_TREND:\n",
    "    # Simple Moving Average (SMA)\n",
    "    df_train[f'SMA_{window}'] = ta.trend.sma_indicator(df_train['Close'], window=window, fillna=False)\n",
    "    # Exponential Moving Average (EMA)\n",
    "    df_train[f'EMA_{window}'] = ta.trend.ema_indicator(df_train['Close'], window=window, fillna=False)\n",
    "    \n",
    "# Moving Average Convergence Divergence (MACD) \n",
    "macd = ta.trend.MACD(df_train['Close'], window_fast=12, window_slow=26, window_sign=9, fillna=False)\n",
    "df_train['MACD_Line'] = macd.macd()\n",
    "df_train['MACD_Signal'] = macd.macd_signal()\n",
    "\n",
    "print(\"Trend Indicators (MA, EMA, MACD) created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Momentum Indicators (RSI)\n",
    "\n",
    "* Momentum indicators measure the speed and change of price movements. \n",
    "\n",
    "* The **Relative Strength Index (RSI)**  is the most popular, indicating overbought or oversold conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum Indicators (RSI) created.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Momentum Indicators\n",
    "RSI_WINDOW = 14 # Standard 14-day RSI\n",
    "df_train[f'RSI_{RSI_WINDOW}'] = ta.momentum.rsi(df_train['Close'], window=RSI_WINDOW, fillna=False)\n",
    "\n",
    "print(\"Momentum Indicators (RSI) created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Volume and Volatility Indicators\n",
    "\n",
    "* Volume provides context on the strength of price movements. \n",
    "\n",
    "* Volatility indicators (like ATR) measure price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume (MFI) and Volatility (ATR) Indicators created.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Volume and Volatility Indicators\n",
    "\n",
    "# Volume-based: Money Flow Index (MFI) \n",
    "df_train['MFI'] = ta.volume.money_flow_index(df_train['High'], df_train['Low'], df_train['Close'], df_train['Volume'], window=14, fillna=False)\n",
    "\n",
    "# Volatility: Average True Range (ATR)\n",
    "df_train['ATR'] = ta.volatility.average_true_range(df_train['High'], df_train['Low'], df_train['Close'], window=14, fillna=False)\n",
    "\n",
    "print(\"Volume (MFI) and Volatility (ATR) Indicators created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Feature Set Cleanup\n",
    "\n",
    "* After generating the Technical Indicators, the first few rows of the DataFrame will contain `NaN` values because they require historical data (e.g., 50 days of data for the 50-day SMA). \n",
    "\n",
    "* We must drop these initial rows, as they cannot be used for training. \n",
    "\n",
    "* We also drop the initial raw price/volume columns, as we will primarily be using the derived features and the target variable (`Log_Return`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped due to TA windows: 49\n",
      "Final Training Data Shape: (57311, 33)\n",
      "Final Feature Set (Columns): ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Symbol', 'Log_Return', 'Simple_Return', 'Price_Change', 'Price_Change_Pct', 'Close_Lag_1', 'Return_Lag_1', 'Close_Lag_2', 'Return_Lag_2', 'Close_Lag_3', 'Return_Lag_3', 'Close_Lag_5', 'Return_Lag_5', 'Close_Lag_10', 'Return_Lag_10', 'SMA_10', 'EMA_10', 'SMA_20', 'EMA_20', 'SMA_50', 'EMA_50', 'MACD_Line', 'MACD_Signal', 'RSI_14', 'MFI', 'ATR']\n",
      "\n",
      "Final Data Head:\n",
      "                                   Open         High          Low        Close  \\\n",
      "Date                                                                            \n",
      "2020-01-02 00:00:00+05:30   935.219909   950.422151   935.214918   947.894287   \n",
      "2020-01-03 00:00:00+05:30   743.390894   743.390894   725.577296   730.549683   \n",
      "2020-01-03 00:00:00+05:30  4109.593667  4129.962198  4059.981839  4092.329102   \n",
      "2020-01-03 00:00:00+05:30   117.492517   118.999434   116.480060   118.245979   \n",
      "2020-01-03 00:00:00+05:30   409.041133   423.863169   407.535397   418.404907   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits      Symbol  \\\n",
      "Date                                                                      \n",
      "2020-01-02 00:00:00+05:30  1578910        0.0           0.0  BAJAJFINSV   \n",
      "2020-01-03 00:00:00+05:30  1417070        0.0           0.0      GRASIM   \n",
      "2020-01-03 00:00:00+05:30   635983        0.0           0.0  ULTRACEMCO   \n",
      "2020-01-03 00:00:00+05:30  6762808        0.0           0.0       WIPRO   \n",
      "2020-01-03 00:00:00+05:30  9457180        0.0           0.0   SUNPHARMA   \n",
      "\n",
      "                           Log_Return  Simple_Return  ...       EMA_10  \\\n",
      "Date                                                  ...                \n",
      "2020-01-02 00:00:00+05:30    0.013467       0.013558  ...   816.213786   \n",
      "2020-01-03 00:00:00+05:30   -0.012738      -0.012657  ...   800.638494   \n",
      "2020-01-03 00:00:00+05:30   -0.006049      -0.006031  ...  1399.127696   \n",
      "2020-01-03 00:00:00+05:30    0.011214       0.011277  ...  1166.240111   \n",
      "2020-01-03 00:00:00+05:30    0.021944       0.022186  ...  1030.270074   \n",
      "\n",
      "                                SMA_20       EMA_20       SMA_50      EMA_50  \\\n",
      "Date                                                                           \n",
      "2020-01-02 00:00:00+05:30   950.668009   888.562638  1011.425033  856.497222   \n",
      "2020-01-03 00:00:00+05:30   856.597483   873.513785  1021.853182  851.558103   \n",
      "2020-01-03 00:00:00+05:30  1038.646499  1180.067625  1070.407848  978.647162   \n",
      "2020-01-03 00:00:00+05:30  1038.507640  1078.941754  1048.285180  944.905939   \n",
      "2020-01-03 00:00:00+05:30   971.524211  1016.033482  1022.618510  924.258840   \n",
      "\n",
      "                            MACD_Line  MACD_Signal     RSI_14        MFI  \\\n",
      "Date                                                                       \n",
      "2020-01-02 00:00:00+05:30  -64.152349   -21.582677  50.192887  47.448483   \n",
      "2020-01-03 00:00:00+05:30  -67.911715   -30.848484  49.291978  48.535930   \n",
      "2020-01-03 00:00:00+05:30  198.092972    14.939807  60.963235  53.165227   \n",
      "2020-01-03 00:00:00+05:30   87.222857    29.396417  47.148040  46.219458   \n",
      "2020-01-03 00:00:00+05:30   23.309116    28.178957  48.104610  46.332228   \n",
      "\n",
      "                                   ATR  \n",
      "Date                                    \n",
      "2020-01-02 00:00:00+05:30   962.855602  \n",
      "2020-01-03 00:00:00+05:30   909.959987  \n",
      "2020-01-03 00:00:00+05:30  1087.778025  \n",
      "2020-01-03 00:00:00+05:30  1294.068812  \n",
      "2020-01-03 00:00:00+05:30  1223.465124  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Drop NaN values created by windowed features\n",
    "df_train_features = df_train.dropna()\n",
    "\n",
    "print(f\"Rows dropped due to TA windows: {df_train.shape[0] - df_train_features.shape[0]}\")\n",
    "print(f\"Final Training Data Shape: {df_train_features.shape}\")\n",
    "print(f\"Final Feature Set (Columns): {df_train_features.columns.tolist()}\")\n",
    "print(\"\\nFinal Data Head:\\n\", df_train_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving the Feature-Rich Dataset\n",
    "\n",
    "* This feature-rich dataset is saved. \n",
    "\n",
    "* It will be the input for all subsequent Machine Learning (ML) and Deep Learning (DL) model notebooks (Notebooks 04 through 09)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved feature-engineered training data to: ../data/processed/nifty50_train_features.csv\n",
      "Ready to begin Classical Model Forecasting in Notebook 04.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save the feature-engineered training data\n",
    "FEATURE_TRAIN_DATA_PATH = '../data/processed/nifty50_train_features.csv'\n",
    "df_train_features.to_csv(FEATURE_TRAIN_DATA_PATH)\n",
    "\n",
    "print(f\"\\nSuccessfully saved feature-engineered training data to: {FEATURE_TRAIN_DATA_PATH}\")\n",
    "print(\"Ready to begin Classical Model Forecasting in Notebook 04.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b89497",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "  1. **Lag Features**: Created lagged price and return variables (1, 2, 3, 5, 10 periods)\n",
    "\n",
    "  2. **Trend Indicators**: Generated SMA, EMA, and MACD across multiple timeframes\n",
    "\n",
    "  3. **Momentum Indicators**: Implemented RSI for overbought/oversold signals\n",
    "\n",
    "  4. **Volume & Volatility**: Added MFI and ATR for market strength analysis\n",
    "\n",
    "  5. **Data Cleaning**: Removed NaN values from windowed calculations\n",
    "\n",
    "  6. **Feature Export**: Saved enriched dataset for subsequent modeling notebooks\n",
    "\n",
    "### Key Technical Features Created:\n",
    "\n",
    "  - **Price Lags**: Close_Lag_1 through Close_Lag_10 for temporal dependencies\n",
    "  \n",
    "  - **Return Lags**: Return_Lag_1 through Return_Lag_10 for momentum analysis\n",
    "  \n",
    "  - **Moving Averages**: SMA/EMA (10, 20, 50) for trend identification\n",
    "  \n",
    "  - **MACD System**: MACD_Line and MACD_Signal for trend convergence\n",
    "  \n",
    "  - **Momentum**: RSI_14 for overbought/oversold conditions\n",
    "  \n",
    "  - **Volume/Volatility**: MFI and ATR for market context\n",
    "\n",
    "### Feature Engineering Results:\n",
    "\n",
    "  - **Original Columns**: Basic OHLCV data\n",
    "  \n",
    "  - **Enhanced Features**: 20+ technical indicators and lag variables\n",
    "  \n",
    "  - **Clean Dataset**: NaN values removed, ready for modeling\n",
    "  \n",
    "  - **Temporal Structure**: Maintains chronological order for time series modeling\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**Notebook 04**: We'll begin classical time series modeling including:\n",
    "- ARIMA model implementation and tuning\n",
    "- Seasonal decomposition analysis\n",
    "- Model evaluation and validation\n",
    "- Baseline performance establishment\n",
    "\n",
    "---\n",
    "\n",
    "### *Next Notebook Preview*\n",
    "\n",
    "With our comprehensive feature set engineered, we're ready to implement classical time series models. Starting with ARIMA, we'll establish baseline performance metrics and validate our feature engineering approach through traditional econometric methods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36722c7d",
   "metadata": {},
   "source": [
    "#### About This Project\n",
    "\n",
    "This notebook is part of the **Stock Price Prediction - NIFTY 50** repository - a comprehensive machine learning pipeline for predicting stock prices using classical to advanced techniques including ARIMA, LSTM, XGBoost, and evolutionary optimization.\n",
    "\n",
    "**Repository:** [`stock-price-prediction-nifty50`](https://github.com/prakash-ukhalkar/stock-price-prediction-nifty50)\n",
    "\n",
    "**Project Features:**\n",
    "- **12 Sequential Notebooks**: From data acquisition to deployment\n",
    "- **Multiple Model Types**: Classical (ARIMA), Traditional ML (SVR, XGBoost), Deep Learning (LSTM, BiLSTM)  \n",
    "- **Advanced Optimization**: Genetic Algorithm and Simulated Annealing\n",
    "- **Production Ready**: Streamlit dashboard and trading strategy backtesting\n",
    "\n",
    "\n",
    "#### **Author**\n",
    "\n",
    "**Prakash Ukhalkar**  \n",
    "[![GitHub](https://img.shields.io/badge/GitHub-prakash--ukhalkar-blue?style=flat&logo=github)](https://github.com/prakash-ukhalkar)\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <sub>Built with care for the quantitative finance and data science community</sub>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_N50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
