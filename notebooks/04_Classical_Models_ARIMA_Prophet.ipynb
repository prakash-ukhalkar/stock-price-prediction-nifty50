{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfd54cf",
   "metadata": {},
   "source": [
    "## **Stock Price Prediction - NIFTY 50**\n",
    "\n",
    "### **Notebook 04: Classical Time Series Forecasting (ARIMA, SARIMA, Prophet)**\n",
    "\n",
    "[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/) [![Statsmodels](https://img.shields.io/badge/Statsmodels-Latest-red)](https://www.statsmodels.org/) [![Prophet](https://img.shields.io/badge/Prophet-Latest-lightblue)](https://facebook.github.io/prophet/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
    "\n",
    "---\n",
    "\n",
    "**Part of the comprehensive learning series:** [Stock Price Prediction - NIFTY 50](https://github.com/prakash-ukhalkar/stock-price-prediction-nifty50)\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Implement classical time series forecasting models (ARIMA, SARIMA, Prophet)\n",
    "- Establish baseline performance metrics for comparison with ML/DL models\n",
    "- Apply automatic hyperparameter tuning for optimal model selection\n",
    "- Evaluate model performance using standard time series metrics\n",
    "- Understand statistical foundations of econometric forecasting\n",
    "\n",
    "**Dataset Scope:** Apply classical models to stationary log returns. Establish benchmarks for advanced modeling.\n",
    "\n",
    "---\n",
    "\n",
    "* This notebook implements and evaluates **classical time series models** for NIFTY-50 returns. \n",
    "\n",
    "* These models provide a crucial benchmark against which the performance of later Machine Learning (ML) and Deep Learning (DL) models will be compared. \n",
    "\n",
    "* We utilize the **Log Returns** for modeling, as they are a stationary time series, satisfying the core assumption of ARIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24b208",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "We load the clean, feature-engineered training and testing data prepared in Notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbb83b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Target Series loaded. Size: 57311\n",
      "Testing Target Series loaded. Size: 14340\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX # Used for final SARIMA fit\n",
    "from pmdarima import auto_arima # For automatic ARIMA hyperparameter search\n",
    "from prophet import Prophet # Facebook Prophet model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define Paths\n",
    "TRAIN_DATA_PATH = '../data/processed/nifty50_train_features.csv'\n",
    "TEST_DATA_PATH = '../data/processed/nifty50_test.csv'\n",
    "MODEL_RESULTS_PATH = '../models/classical_model_results.csv'\n",
    "\n",
    "# Load the training and testing datasets (Log Returns is the primary target)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH, index_col='Date', parse_dates=True)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH, index_col='Date', parse_dates=True)\n",
    "\n",
    "y_train = train_df['Log_Return'].dropna() # Target series for classical models\n",
    "y_test = test_df['Log_Return'].dropna()   # Actual values for testing\n",
    "\n",
    "forecast_steps = len(y_test)\n",
    "\n",
    "print(f\"Training Target Series loaded. Size: {y_train.shape[0]}\")\n",
    "print(f\"Testing Target Series loaded. Size: {y_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c2db0",
   "metadata": {},
   "source": [
    "## 2. Model I: ARIMA (AutoRegressive Integrated Moving Average)\n",
    "\n",
    "* ARIMA models use lagged observations (AR), differencing (I), and lagged forecast errors (MA). \n",
    "\n",
    "* We use `auto_arima` to search for the optimal combination of non-seasonal orders ($p, d, q$) that minimizes the **Akaike Information Criterion (AIC)**. \n",
    "\n",
    "* We set $d=0$ since we model the already stationary **Log Returns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbe06785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for optimal ARIMA(p,d,q) order...\n",
      "--- Auto ARIMA Results ---\n",
      "--- Auto ARIMA Results ---\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                57311\n",
      "Model:               SARIMAX(2, 0, 1)   Log Likelihood              148571.640\n",
      "Date:                Sun, 19 Oct 2025   AIC                        -297133.280\n",
      "Time:                        23:12:58   BIC                        -297088.498\n",
      "Sample:                             0   HQIC                       -297119.340\n",
      "                              - 57311                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept   2.102e-05   1.29e-05      1.628      0.103   -4.28e-06    4.63e-05\n",
      "ar.L1          0.9426      0.003    273.266      0.000       0.936       0.949\n",
      "ar.L2          0.0270      0.003      8.776      0.000       0.021       0.033\n",
      "ma.L1         -0.8302      0.002   -419.952      0.000      -0.834      -0.826\n",
      "sigma2         0.0003    6.7e-07    489.185      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):            568436.04\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.46   Skew:                             0.09\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.43\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Optimal ARIMA order: (2, 0, 1)\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                57311\n",
      "Model:               SARIMAX(2, 0, 1)   Log Likelihood              148571.640\n",
      "Date:                Sun, 19 Oct 2025   AIC                        -297133.280\n",
      "Time:                        23:12:58   BIC                        -297088.498\n",
      "Sample:                             0   HQIC                       -297119.340\n",
      "                              - 57311                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept   2.102e-05   1.29e-05      1.628      0.103   -4.28e-06    4.63e-05\n",
      "ar.L1          0.9426      0.003    273.266      0.000       0.936       0.949\n",
      "ar.L2          0.0270      0.003      8.776      0.000       0.021       0.033\n",
      "ma.L1         -0.8302      0.002   -419.952      0.000      -0.834      -0.826\n",
      "sigma2         0.0003    6.7e-07    489.185      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):            568436.04\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.46   Skew:                             0.09\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.43\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Optimal ARIMA order: (2, 0, 1)\n",
      "ARIMA Forecast generated for 14340 periods.\n",
      "ARIMA Forecast generated for 14340 periods.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Find Optimal ARIMA Order using auto_arima\n",
    "\n",
    "print(\"Searching for optimal ARIMA(p,d,q) order...\")\n",
    "\n",
    "arima_model_fit = auto_arima(y_train, \n",
    "                             start_p=1, start_q=1, \n",
    "                             max_p=5, max_q=5, \n",
    "                             m=1, # Non-seasonal model\n",
    "                             d=0, \n",
    "                             suppress_warnings=True, \n",
    "                             stepwise=True, \n",
    "                             error_action='ignore')\n",
    "\n",
    "print(\"--- Auto ARIMA Results ---\")\n",
    "print(arima_model_fit.summary())\n",
    "optimal_order_arima = arima_model_fit.order\n",
    "print(f\"Optimal ARIMA order: {optimal_order_arima}\")\n",
    "\n",
    "# Generate Forecast using the best ARIMA model\n",
    "arima_forecast = arima_model_fit.predict(n_periods=forecast_steps)\n",
    "\n",
    "# CRITICAL FIX: Convert prediction result to a NumPy array's values before mapping to Series \n",
    "# This ensures a clean array is used, preventing NaN/alignment issues in evaluation.\n",
    "arima_forecast_series = pd.Series(arima_forecast.values, index=y_test.index)\n",
    "\n",
    "print(f\"ARIMA Forecast generated for {forecast_steps} periods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaabf77",
   "metadata": {},
   "source": [
    "## 3. Model II: SARIMA (Seasonal ARIMA)\n",
    "\n",
    "* SARIMA is used to capture seasonal dependencies. Since the `auto_arima` search is highly memory-intensive for long daily series with $m=21$ (a memory error risk), we use a safe, two-step approach:\n",
    "  \n",
    "  1.  **Search on Subset:** Use the last year of data to efficiently find the optimal seasonal parameters.\n",
    "  \n",
    "  2.  **Fit on Full Data:** Use the identified parameters to fit the final SARIMAX model on the entire `y_train` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3c79ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA search is memory-intensive. Using the last 252 trading days (approx. 1 year) of data to search for parameters...\n",
      "Optimal SARIMA order found on subset: (1, 0, 1) x (0, 0, 0, 21) (m=21)\n",
      "Optimal SARIMA order found on subset: (1, 0, 1) x (0, 0, 0, 21) (m=21)\n",
      "--- Full SARIMA Model Fit Summary (using optimal parameters) ---\n",
      "--- Full SARIMA Model Fit Summary (using optimal parameters) ---\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:             Log_Return   No. Observations:                57311\n",
      "Model:               SARIMAX(1, 0, 1)   Log Likelihood              148548.498\n",
      "Date:                Sun, 19 Oct 2025   AIC                        -297090.995\n",
      "Time:                        23:14:13   BIC                        -297064.127\n",
      "Sample:                             0   HQIC                       -297082.632\n",
      "                              - 57311                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.9720      0.001   1524.292      0.000       0.971       0.973\n",
      "ma.L1         -0.8398      0.002   -554.096      0.000      -0.843      -0.837\n",
      "sigma2         0.0003   6.69e-07    490.439      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  21.60   Jarque-Bera (JB):            569902.53\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.46   Skew:                             0.09\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.45\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:             Log_Return   No. Observations:                57311\n",
      "Model:               SARIMAX(1, 0, 1)   Log Likelihood              148548.498\n",
      "Date:                Sun, 19 Oct 2025   AIC                        -297090.995\n",
      "Time:                        23:14:13   BIC                        -297064.127\n",
      "Sample:                             0   HQIC                       -297082.632\n",
      "                              - 57311                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.9720      0.001   1524.292      0.000       0.971       0.973\n",
      "ma.L1         -0.8398      0.002   -554.096      0.000      -0.843      -0.837\n",
      "sigma2         0.0003   6.69e-07    490.439      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                  21.60   Jarque-Bera (JB):            569902.53\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.46   Skew:                             0.09\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.45\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "SARIMA Forecast generated using integer indices 57311 to 71650.\n",
      "Total 14340 periods mapped to test index.\n",
      "SARIMA Forecast generated using integer indices 57311 to 71650.\n",
      "Total 14340 periods mapped to test index.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Find Optimal SARIMA Order (Memory-Safe Windowing)\n",
    "print(\"SARIMA search is memory-intensive. Using the last 252 trading days (approx. 1 year) of data to search for parameters...\")\n",
    "\n",
    "# Create a subset of the training data for parameter search only\n",
    "y_train_subset = y_train.tail(252) \n",
    "\n",
    "# --- Step 1: Search on Subset ---\n",
    "# Restricting max_P/Q = 1 to manage memory\n",
    "sarima_search_fit = auto_arima(y_train_subset, \n",
    "                              start_p=0, start_q=0, \n",
    "                              max_p=2, max_q=2, \n",
    "                              m=21, # Seasonal period (approx. 1 month of trading days)\n",
    "                              start_P=0, start_Q=0,\n",
    "                              max_P=1, max_Q=1, \n",
    "                              d=0, D=0,\n",
    "                              suppress_warnings=True, \n",
    "                              stepwise=True, \n",
    "                              error_action='ignore',\n",
    "                              trace=False)\n",
    "\n",
    "optimal_sarima_order = sarima_search_fit.order\n",
    "optimal_seasonal_order = sarima_search_fit.seasonal_order\n",
    "\n",
    "print(f\"Optimal SARIMA order found on subset: {optimal_sarima_order} x {optimal_seasonal_order} (m=21)\")\n",
    "\n",
    "\n",
    "# --- Step 2: Fit Model on FULL Training Data ---\n",
    "sarima_full_model = SARIMAX(y_train, \n",
    "                            order=optimal_sarima_order, \n",
    "                            seasonal_order=optimal_seasonal_order, \n",
    "                            enforce_stationarity=False, \n",
    "                            enforce_invertibility=False)\n",
    "\n",
    "sarima_model_fit = sarima_full_model.fit(disp=False)\n",
    "\n",
    "print(\"--- Full SARIMA Model Fit Summary (using optimal parameters) ---\")\n",
    "print(sarima_model_fit.summary())\n",
    "\n",
    "# --- Step 3: Generate Forecast using Integer Indices (Necessary for OOS prediction) ---\n",
    "\n",
    "# Calculate integer steps relative to the end of the training data\n",
    "n_train = len(y_train)\n",
    "start_step = n_train\n",
    "end_step = n_train + forecast_steps - 1\n",
    "\n",
    "# Use integer steps for out-of-sample prediction, as required by statsmodels\n",
    "sarima_forecast = sarima_model_fit.predict(start=start_step, end=end_step)\n",
    "sarima_forecast_series = pd.Series(sarima_forecast.values, index=y_test.index)\n",
    "\n",
    "print(f\"SARIMA Forecast generated using integer indices {start_step} to {end_step}.\")\n",
    "print(f\"Total {forecast_steps} periods mapped to test index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33911cac",
   "metadata": {},
   "source": [
    "## 4. Model III: Facebook Prophet\n",
    "\n",
    "* Prophet is an additive model that easily handles trend and multiple seasonalities. \n",
    "\n",
    "* It requires the data to be in a DataFrame with columns named `ds` (DateStamp) and `y` (target value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a553da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet training data head (Timezone removed):\n",
      "          ds         y\n",
      "0 2020-01-02  0.013467\n",
      "1 2020-01-03 -0.012738\n",
      "2 2020-01-03 -0.006049\n",
      "3 2020-01-03  0.011214\n",
      "4 2020-01-03  0.021944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:15:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:16:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:16:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet model fitted and future dataframe created.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Prepare Data and Fit Prophet Model\n",
    "\n",
    "# Prophet data preparation\n",
    "prophet_df_train = y_train.reset_index()\n",
    "prophet_df_train.columns = ['ds', 'y']\n",
    "\n",
    "# CRITICAL FIX: Remove Timezone before fitting Prophet\n",
    "if prophet_df_train['ds'].dt.tz is not None:\n",
    "    prophet_df_train['ds'] = prophet_df_train['ds'].dt.tz_localize(None)\n",
    "\n",
    "print(\"Prophet training data head (Timezone removed):\")\n",
    "print(prophet_df_train.head())\n",
    "\n",
    "# Initialize and Fit Model\n",
    "prophet_model = Prophet(yearly_seasonality=True, daily_seasonality=False)\n",
    "prophet_model.fit(prophet_df_train)\n",
    "\n",
    "# Create future dataframe for forecasting\n",
    "prophet_future = prophet_model.make_future_dataframe(periods=forecast_steps, include_history=False)\n",
    "\n",
    "print(\"Prophet model fitted and future dataframe created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8085cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet Forecast Head (Log Returns):\n",
      " Date\n",
      "2024-08-22 00:00:00+05:30    0.001505\n",
      "2024-08-22 00:00:00+05:30    0.001962\n",
      "2024-08-22 00:00:00+05:30    0.008448\n",
      "2024-08-22 00:00:00+05:30   -0.000470\n",
      "2024-08-22 00:00:00+05:30    0.003674\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Generate Prophet Forecast\n",
    "\n",
    "prophet_forecast_results = prophet_model.predict(prophet_future)\n",
    "\n",
    "# Extract the main forecast (yhat) and map to the test index\n",
    "prophet_forecast = prophet_forecast_results['yhat'].values\n",
    "prophet_forecast_series = pd.Series(prophet_forecast, index=y_test.index)\n",
    "\n",
    "print(\"Prophet Forecast Head (Log Returns):\\n\", prophet_forecast_series.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09056027",
   "metadata": {},
   "source": [
    "## 5. Preliminary Evaluation and Results Consolidation\n",
    "\n",
    "* We calculate standard error metrics (MSE, MAE, RMSE) for the forecasts generated by the three classical models against the actual test data (`y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a091a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classical Model Evaluation (Log Returns) ---\n",
      "              MSE       MAE      RMSE\n",
      "Model                                \n",
      "ARIMA    0.000261  0.010981  0.016141\n",
      "SARIMA   0.000260  0.010954  0.016126\n",
      "Prophet  0.000273  0.011414  0.016520\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define Evaluation Function (Robust against NaNs)\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \n",
    "    # 1. Synchronize the series indices and drop NaNs from both simultaneously\n",
    "    # This fixes the NaN/alignment issue in evaluation.\n",
    "    y_aligned = pd.concat([y_true, y_pred], axis=1).dropna()\n",
    "    y_true_clean = y_aligned.iloc[:, 0].values\n",
    "    y_pred_clean = y_aligned.iloc[:, 1].values\n",
    "    \n",
    "    # Check for empty data after dropping NaNs\n",
    "    if y_true_clean.size == 0:\n",
    "        print(f\"Warning: Model {model_name} generated all NaNs or mismatch.\")\n",
    "        return {'Model': model_name, 'MSE': np.nan, 'MAE': np.nan, 'RMSE': np.nan}\n",
    "        \n",
    "    mse = mean_squared_error(y_true_clean, y_pred_clean)\n",
    "    mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    results = {'Model': model_name, 'MSE': mse, 'MAE': mae, 'RMSE': rmse}\n",
    "    return results\n",
    "\n",
    "# Evaluate Models\n",
    "arima_results = evaluate_model(y_test, arima_forecast_series, 'ARIMA')\n",
    "sarima_results = evaluate_model(y_test, sarima_forecast_series, 'SARIMA')\n",
    "prophet_results = evaluate_model(y_test, prophet_forecast_series, 'Prophet')\n",
    "\n",
    "results_df = pd.DataFrame([arima_results, sarima_results, prophet_results])\n",
    "\n",
    "print(\"--- Classical Model Evaluation (Log Returns) ---\")\n",
    "print(results_df.set_index('Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04e879",
   "metadata": {},
   "source": [
    "## 6. Final Save\n",
    "\n",
    "The evaluation results are saved to the `models/` directory for later consolidation and comparison in Notebook 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "285da59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classical model evaluation results saved to: ../models/classical_model_results.csv\n",
      "Proceed to Notebook 05 for Machine Learning (KNN and SVR) implementation.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Classical Model Results\n",
    "results_df.to_csv(MODEL_RESULTS_PATH, index=False)\n",
    "\n",
    "print(f\"\\nClassical model evaluation results saved to: {MODEL_RESULTS_PATH}\")\n",
    "print(\"Proceed to Notebook 05 for Machine Learning (KNN and SVR) implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd464f58",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "  1. **ARIMA Modeling**: Implemented automated ARIMA with optimal (p,d,q) parameter search\n",
    "\n",
    "  2. **SARIMA Analysis**: Extended to seasonal patterns with memory-safe parameter optimization\n",
    "\n",
    "  3. **Prophet Forecasting**: Applied Facebook's robust time series framework with timezone handling\n",
    "\n",
    "  4. **Model Evaluation**: Calculated MSE, MAE, and RMSE with robust NaN handling\n",
    "\n",
    "  5. **Baseline Establishment**: Created benchmarks for subsequent ML/DL model evaluation\n",
    "\n",
    "  6. **Results Export**: Saved performance metrics for comprehensive model comparison\n",
    "\n",
    "### Key Classical Model Insights:\n",
    "\n",
    "  - **ARIMA Performance**: Optimal parameters identified through AIC minimization\n",
    "  \n",
    "  - **SARIMA Optimization**: Memory-safe approach using data subset for parameter search\n",
    "  \n",
    "  - **Prophet Robustness**: Handled trend and seasonality patterns with timezone normalization\n",
    "  \n",
    "  - **Stationarity Advantage**: Log returns satisfied classical model assumptions\n",
    "  \n",
    "  - **Evaluation Framework**: Robust metrics calculation with NaN alignment handling\n",
    "\n",
    "### Technical Implementation Notes:\n",
    "\n",
    "  - **Memory Management**: SARIMA parameter search optimized for large datasets\n",
    "  \n",
    "  - **Data Alignment**: Proper index synchronization for accurate evaluation\n",
    "  \n",
    "  - **Timezone Handling**: Prophet compatibility ensured through timezone removal\n",
    "  \n",
    "  - **Forecast Validation**: Integer-based out-of-sample prediction for SARIMA\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**Notebook 05**: We'll advance to traditional Machine Learning models including:\n",
    "- K-Nearest Neighbors (KNN) for pattern recognition\n",
    "- Support Vector Regression (SVR) for non-linear relationships\n",
    "- Performance comparison with classical benchmarks\n",
    "- Feature importance analysis using engineered indicators\n",
    "\n",
    "---\n",
    "\n",
    "### *Next Notebook Preview*\n",
    "\n",
    "Having established classical time series benchmarks, we'll now explore how traditional machine learning algorithms perform on our feature-engineered dataset, leveraging the technical indicators and lag variables created in Notebook 03.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d805bbb",
   "metadata": {},
   "source": [
    "#### About This Project\n",
    "\n",
    "This notebook is part of the **Stock Price Prediction - NIFTY 50** repository - a comprehensive machine learning pipeline for predicting stock prices using classical to advanced techniques including ARIMA, LSTM, XGBoost, and evolutionary optimization.\n",
    "\n",
    "**Repository:** [`stock-price-prediction-nifty50`](https://github.com/prakash-ukhalkar/stock-price-prediction-nifty50)\n",
    "\n",
    "**Project Features:**\n",
    "- **12 Sequential Notebooks**: From data acquisition to deployment\n",
    "- **Multiple Model Types**: Classical (ARIMA), Traditional ML (SVR, XGBoost), Deep Learning (LSTM, BiLSTM)  \n",
    "- **Advanced Optimization**: Genetic Algorithm and Simulated Annealing\n",
    "- **Production Ready**: Streamlit dashboard and trading strategy backtesting\n",
    "\n",
    "\n",
    "#### **Author**\n",
    "\n",
    "**Prakash Ukhalkar**  \n",
    "[![GitHub](https://img.shields.io/badge/GitHub-prakash--ukhalkar-blue?style=flat&logo=github)](https://github.com/prakash-ukhalkar)\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <sub>Built with care for the quantitative finance and data science community</sub>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_N50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
